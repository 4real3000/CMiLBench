# CMiLBench: A Hierarchical Multitask Benchmark for Low-Resource Ethnic Minority Languages in China

## åŸºå‡†ç®€ä»‹

**CMiLBench** æ˜¯ä¸€ä¸ªå±‚æ¬¡åŒ–çš„å¤šä»»åŠ¡è¯„æµ‹åŸºå‡†ï¼Œä¸“ä¸ºä¸­å›½å°‘æ•°æ°‘æ—è¯­è¨€ï¼ˆè—è¯­ `bo`ã€è’™å¤è¯­ `mn`ã€ç»´å¾å°”è¯­ `ug`ï¼‰è®¾è®¡ã€‚è¯¥åŸºå‡†æ—¨åœ¨ç³»ç»Ÿè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨ä½èµ„æºè¯­è¨€ç¯å¢ƒä¸‹çš„ç†è§£ã€ç”Ÿæˆä¸å®‰å…¨å¯¹é½èƒ½åŠ›ã€‚

CMiLBench åŒ…å«ä»¥ä¸‹ä¸‰å¤§ä»»åŠ¡ç±»åˆ«ï¼Œå…±è®¡ 17 ä¸ªå­ä»»åŠ¡ï¼Œè¦†ç›–è¯­è¨€åŸºç¡€èƒ½åŠ›ã€æ–‡åŒ–çŸ¥è¯†èƒ½åŠ›ä¸å¤šè¯­è¨€å®‰å…¨æ€§ï¼š

- åŸºç¡€ä»»åŠ¡ï¼ˆFoundation Tasksï¼‰
- æ°‘æ—çŸ¥è¯†ä»»åŠ¡ï¼ˆChinese Minority Knowledge Tasksï¼‰
- å®‰å…¨å¯¹é½ä»»åŠ¡ï¼ˆSafety Alignment Tasksï¼‰

### ä»»åŠ¡åˆ†å¸ƒæ€»è§ˆå›¾

![task_categories_overview](./assets/category.png)

---

## æ–‡ä»¶ç»“æ„è¯´æ˜

```bash
CMiLBench/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Chinese_Minority_Knowledge_Tasks/
â”‚   â”‚   â”œâ”€â”€ Minority_Culture_QA/
â”‚   â”‚   â”œâ”€â”€ Minority_Domain_Competence/
â”‚   â”‚   â”œâ”€â”€ Minority_Language_Expressions/
â”‚   â”‚   â”œâ”€â”€ Minority_Language_Instruction_QA/
â”‚   â”‚   â”œâ”€â”€ Minority_Language_Understanding/
â”‚   â”‚   â””â”€â”€ Minority_Machine_Translation/
â”‚   â”œâ”€â”€ Foundation_Tasks/
â”‚   â”‚   â”œâ”€â”€ Coreference_Resolution/
â”‚   â”‚   â”œâ”€â”€ General_Domain_Competence/
â”‚   â”‚   â”œâ”€â”€ Machine_Reading_Comprehension/
â”‚   â”‚   â”œâ”€â”€ Math_Reasoning/
â”‚   â”‚   â”œâ”€â”€ Natural_Language_Inference/
â”‚   â”‚   â””â”€â”€ Text_Classification/
â”‚   â””â”€â”€ Safety_Alignment_Tasks/
â”‚       â”œâ”€â”€ Commercial_Compliance_Check/
â”‚       â”œâ”€â”€ Discrimination_Detection/
â”‚       â”œâ”€â”€ Rights_Protection_Evaluation/
â”‚       â”œâ”€â”€ Service_Safety_Evaluation/
â”‚       â””â”€â”€ Value_Alignment_Assessment/
â”œâ”€â”€ inference/                    # æ¨ç†è„šæœ¬
â”‚   â”œâ”€â”€ infer_api.py
â”‚   â”œâ”€â”€ infer_api.sh
â”‚   â”œâ”€â”€ infer_vllm.py
â”‚   â””â”€â”€ infer_vllm.sh
â”œâ”€â”€ evaluation/                  # è¯„ä¼°è„šæœ¬
â”‚   â”œâ”€â”€ answer_extraction.py
â”‚   â”œâ”€â”€ comprehensive_evaluation.py
â”‚   â””â”€â”€ llm_evaluation.py.py
â””â”€â”€ README.md

```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…æ­¥éª¤

```bash
# 1. å…‹éš†ä»“åº“
git clone https://github.com/your-repo/CMiLBench.git
cd CMiLBench

# 2. åˆ›å»ºcondaç¯å¢ƒ
conda create -n cmilbench python=3.11
conda activate cmilbench

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### å¼€å§‹è¯„æµ‹

#### 1. APIæ¨¡å‹æ¨ç†ï¼ˆAPI-based Inferenceï¼‰

**ç¬¬ä¸€æ­¥ï¼šé…ç½®APIä¿¡æ¯**

åœ¨æ‰§è¡Œè„šæœ¬ä¸­é…ç½®æ‚¨çš„APIå¯†é’¥å’Œåœ°å€ï¼š

```bash
# ç¼–è¾‘æ¨ç†è„šæœ¬
nano inference/infer_api.sh

# ä¿®æ”¹ä»¥ä¸‹é…ç½®é¡¹ï¼ˆå¿…éœ€ï¼‰ï¼š
model_name="gpt-4o"                   # æ‚¨è¦ä½¿ç”¨çš„æ¨¡å‹åç§°
api_key="your_api_key_here"           # æ›¿æ¢ä¸ºæ‚¨çš„å®é™…APIå¯†é’¥
api_base="https://api.openai.com/v1"  # æ›¿æ¢ä¸ºæ‚¨çš„APIåœ°å€
BASE_PATH="/path/to/CMiLBench"        # ä¿®æ”¹ä¸ºå®é™…çš„æ•°æ®é›†è·¯å¾„
INFER_SCRIPT="/path/to/infer_vllm.py" # æ¨ç†è„šæœ¬è·¯å¾„
```

**ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œæ¨ç†**

```bash
# è¿è¡Œå®Œæ•´æ¨ç†ï¼ˆæ‰€æœ‰ä»»åŠ¡ã€æ‰€æœ‰è¯­è¨€ï¼‰
cd inference
bash infer_api.sh
```

#### 2. æœ¬åœ°æ¨¡å‹æ¨ç†ï¼ˆLocal Model Inferenceï¼‰

**ç¬¬ä¸€æ­¥ï¼šé…ç½®æ¨¡å‹å’Œæ•°æ®é›†è·¯å¾„**

åœ¨æ‰§è¡Œè„šæœ¬ä¸­é…ç½®æ‚¨çš„æœ¬åœ°æ¨¡å‹å’Œæ•°æ®é›†è·¯å¾„ï¼š

```bash
# ç¼–è¾‘æ¨ç†è„šæœ¬
nano inference/infer_vllm.sh

# ä¿®æ”¹ä»¥ä¸‹é…ç½®é¡¹ï¼ˆå¿…éœ€ï¼‰ï¼š
model_type="qwen"                      # æ¨¡å‹ç±»å‹: qwen, aya, llama, mistral, gemma
model_path="/path/to/your/model"       # æ›¿æ¢ä¸ºæ‚¨çš„æœ¬åœ°æ¨¡å‹è·¯å¾„
model_name="gpt-4o"                    # æ‚¨è¦ä½¿ç”¨çš„æ¨¡å‹åç§°
BASE_PATH="/path/to/CMiLBench"         # ä¿®æ”¹ä¸ºå®é™…çš„æ•°æ®é›†è·¯å¾„
INFER_SCRIPT="/path/to/infer_vllm.py"  # æ¨ç†è„šæœ¬è·¯å¾„

# GPUé…ç½®ï¼ˆå¯é€‰ï¼‰ï¼š
export CUDA_VISIBLE_DEVICES=0          # æŒ‡å®šä½¿ç”¨çš„GPU
gpu_memory_utilization=0.9             # GPUå†…å­˜ä½¿ç”¨ç‡
tensor_parallel_size=1                 # å¼ é‡å¹¶è¡Œå¤§å°
```

**ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œæ¨ç†**

```bash
# è¿è¡Œå®Œæ•´æ¨ç†ï¼ˆæ‰€æœ‰ä»»åŠ¡ã€æ‰€æœ‰è¯­è¨€ï¼‰
cd inference
bash infer_vllm.sh
```
#### è¾“å‡ºç»“æœ ####

æ¨ç†å®Œæˆåï¼Œç»“æœå°†ä¿å­˜åœ¨ä»¥ä¸‹ç›®å½•ç»“æ„ä¸­ï¼š

```
output/
â”œâ”€â”€ {model_name}/
â”‚   â”œâ”€â”€ Foundation_Tasks/
â”‚   â”‚   â”œâ”€â”€ Text_Classification/{lang}/
â”‚   â”‚   â”œâ”€â”€ Natural_Language_Inference/{lang}/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Chinese_Minority_Knowledge_Tasks/
â”‚   â”‚   â”œâ”€â”€ Minority_Culture_QA/{lang}/
â”‚   â”‚   â”œâ”€â”€ Minority_Machine_Translation/{lang}/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ Safety_Alignment_Tasks/
â”‚       â”œâ”€â”€ Commercial_Compliance_Check/{lang}/
â”‚       â”œâ”€â”€ Discrimination_Detection/{lang}/
â”‚       â””â”€â”€ ...
```

æ¯ä¸ªä»»åŠ¡çš„ç»“æœæ–‡ä»¶åŒ…å«ï¼š
- `id`: æ ·æœ¬ID
- `pred`: æ¨¡å‹é¢„æµ‹ç»“æœ
- `gold`: æ ‡å‡†ç­”æ¡ˆ
- 
#### 3. ç»“æœè¯„ä¼°ï¼ˆEvaluationï¼‰

#### ç¬¬ä¸€æ­¥ï¼šç­”æ¡ˆæå–

å¯¹æ¨ç†ç»“æœè¿›è¡Œæ ‡å‡†åŒ–ç­”æ¡ˆæå–ï¼Œä¸ºåç»­è¯„ä¼°åšå‡†å¤‡ï¼š

```bash
# ç¼–è¾‘ç­”æ¡ˆæå–è„šæœ¬
nano evaluation/answer_extraction.py

# æ‰§è¡Œç­”æ¡ˆæå–
python evaluation/answer_extraction.py \
    --base_path "/path/to/output"              # ğŸ“ æ¨ç†ç»“æœçš„åŸºç¡€è·¯å¾„
    --output_dir "/path/to/extracted_answers"  # ğŸ“ æå–ç­”æ¡ˆçš„è¾“å‡ºç›®å½•
    --model "gpt-4o"                          # ğŸ¯ æŒ‡å®šå¤„ç†çš„æ¨¡å‹ï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™å¤„ç†æ‰€æœ‰æ¨¡å‹ï¼‰
    --task "Text_Classification"              # ğŸ“‹ æŒ‡å®šå¤„ç†çš„ä»»åŠ¡ï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™å¤„ç†æ‰€æœ‰ä»»åŠ¡ï¼‰
    --language "bo"                           # ğŸŒ æŒ‡å®šå¤„ç†çš„è¯­è¨€ï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™å¤„ç†æ‰€æœ‰è¯­è¨€ï¼‰
```
